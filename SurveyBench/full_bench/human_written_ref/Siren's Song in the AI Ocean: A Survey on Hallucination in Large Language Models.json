{
    "1706.03762": {
        "arxivId": "1706.03762",
        "title": "Attention is All you Need"
    },
    "1810.04805": {
        "arxivId": "1810.04805",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    },
    "2005.14165": {
        "arxivId": "2005.14165",
        "title": "Language Models are Few-Shot Learners"
    },
    "1907.11692": {
        "arxivId": "1907.11692",
        "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
    },
    "1910.10683": {
        "arxivId": "1910.10683",
        "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
    },
    "1707.06347": {
        "arxivId": "1707.06347",
        "title": "Proximal Policy Optimization Algorithms"
    },
    "1910.13461": {
        "arxivId": "1910.13461",
        "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"
    },
    "2203.02155": {
        "arxivId": "2203.02155",
        "title": "Training language models to follow instructions with human feedback"
    },
    "2302.13971": {
        "arxivId": "2302.13971",
        "title": "LLaMA: Open and Efficient Foundation Language Models"
    },
    "2303.08774": {
        "arxivId": "2303.08774",
        "title": "GPT-4 Technical Report"
    },
    "2307.09288": {
        "arxivId": "2307.09288",
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
    },
    "1909.11942": {
        "arxivId": "1909.11942",
        "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
    },
    "2201.11903": {
        "arxivId": "2201.11903",
        "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models"
    },
    "1706.04599": {
        "arxivId": "1706.04599",
        "title": "On Calibration of Modern Neural Networks"
    },
    "2204.02311": {
        "arxivId": "2204.02311",
        "title": "PaLM: Scaling Language Modeling with Pathways"
    },
    "1904.09675": {
        "arxivId": "1904.09675",
        "title": "BERTScore: Evaluating Text Generation with BERT"
    },
    "2005.11401": {
        "arxivId": "2005.11401",
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    "2109.01652": {
        "arxivId": "2109.01652",
        "title": "Finetuned Language Models Are Zero-Shot Learners"
    },
    "1904.09751": {
        "arxivId": "1904.09751",
        "title": "The Curious Case of Neural Text Degeneration"
    },
    "2210.11416": {
        "arxivId": "2210.11416",
        "title": "Scaling Instruction-Finetuned Language Models"
    },
    "2304.08485": {
        "arxivId": "2304.08485",
        "title": "Visual Instruction Tuning"
    },
    "2203.11171": {
        "arxivId": "2203.11171",
        "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"
    },
    "2211.05100": {
        "arxivId": "2211.05100",
        "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"
    },
    "2303.18223": {
        "arxivId": "2303.18223",
        "title": "A Survey of Large Language Models"
    },
    "2204.05862": {
        "arxivId": "2204.05862",
        "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
    },
    "2212.10560": {
        "arxivId": "2212.10560",
        "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions"
    },
    "2202.03629": {
        "arxivId": "2202.03629",
        "title": "Survey of Hallucination in Natural Language Generation"
    },
    "2210.03629": {
        "arxivId": "2210.03629",
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models"
    },
    "2003.08271": {
        "arxivId": "2003.08271",
        "title": "Pre-trained models for natural language processing: A survey"
    },
    "2109.07958": {
        "arxivId": "2109.07958",
        "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods"
    },
    "1611.04230": {
        "arxivId": "1611.04230",
        "title": "SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents"
    },
    "2304.03442": {
        "arxivId": "2304.03442",
        "title": "Generative Agents: Interactive Simulacra of Human Behavior"
    },
    "2302.04023": {
        "arxivId": "2302.04023",
        "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"
    },
    "2210.02414": {
        "arxivId": "2210.02414",
        "title": "GLM-130B: An Open Bilingual Pre-trained Model"
    },
    "2112.09332": {
        "arxivId": "2112.09332",
        "title": "WebGPT: Browser-assisted question-answering with human feedback"
    },
    "2307.03172": {
        "arxivId": "2307.03172",
        "title": "Lost in the Middle: How Language Models Use Long Contexts"
    },
    "2202.05262": {
        "arxivId": "2202.05262",
        "title": "Locating and Editing Factual Associations in GPT"
    },
    "2005.00661": {
        "arxivId": "2005.00661",
        "title": "On Faithfulness and Factuality in Abstractive Summarization"
    },
    "2307.15043": {
        "arxivId": "2307.15043",
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models"
    },
    "2112.04426": {
        "arxivId": "2112.04426",
        "title": "Improving language models by retrieving from trillions of tokens"
    },
    "2307.03109": {
        "arxivId": "2307.03109",
        "title": "A Survey on Evaluation of Large Language Models"
    },
    "2002.08910": {
        "arxivId": "2002.08910",
        "title": "How Much Knowledge Can You Pack into the Parameters of a Language Model?"
    },
    "2111.01243": {
        "arxivId": "2111.01243",
        "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"
    },
    "2304.14178": {
        "arxivId": "2304.14178",
        "title": "mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"
    },
    "1711.01731": {
        "arxivId": "1711.01731",
        "title": "A Survey on Dialogue Systems: Recent Advances and New Frontiers"
    },
    "1910.12840": {
        "arxivId": "1910.12840",
        "title": "Evaluating the Factual Consistency of Abstractive Text Summarization"
    },
    "1805.01954": {
        "arxivId": "1805.01954",
        "title": "Behavioral Cloning from Observation"
    },
    "2306.01116": {
        "arxivId": "2306.01116",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"
    },
    "2305.11206": {
        "arxivId": "2305.11206",
        "title": "LIMA: Less Is More for Alignment"
    },
    "2305.16291": {
        "arxivId": "2305.16291",
        "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models"
    },
    "2307.02483": {
        "arxivId": "2307.02483",
        "title": "Jailbroken: How Does LLM Safety Training Fail?"
    },
    "2207.05221": {
        "arxivId": "2207.05221",
        "title": "Language Models (Mostly) Know What They Know"
    },
    "2304.03277": {
        "arxivId": "2304.03277",
        "title": "Instruction Tuning with GPT-4"
    },
    "2304.07327": {
        "arxivId": "2304.07327",
        "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment"
    },
    "2301.12652": {
        "arxivId": "2301.12652",
        "title": "REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    "2104.08164": {
        "arxivId": "2104.08164",
        "title": "Editing Factual Knowledge in Language Models"
    },
    "2305.10355": {
        "arxivId": "2305.10355",
        "title": "Evaluating Object Hallucination in Large Vision-Language Models"
    },
    "2305.14251": {
        "arxivId": "2305.14251",
        "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"
    },
    "2302.00093": {
        "arxivId": "2302.00093",
        "title": "Large Language Models Can Be Easily Distracted by Irrelevant Context"
    },
    "2305.20050": {
        "arxivId": "2305.20050",
        "title": "Let's Verify Step by Step"
    },
    "2210.07229": {
        "arxivId": "2210.07229",
        "title": "Mass-Editing Memory in a Transformer"
    },
    "2305.14325": {
        "arxivId": "2305.14325",
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent Debate"
    },
    "2005.03754": {
        "arxivId": "2005.03754",
        "title": "FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"
    },
    "2302.00083": {
        "arxivId": "2302.00083",
        "title": "In-Context Retrieval-Augmented Language Models"
    },
    "2112.07899": {
        "arxivId": "2112.07899",
        "title": "Large Dual Encoders Are Generalizable Retrievers"
    },
    "2212.10511": {
        "arxivId": "2212.10511",
        "title": "When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"
    },
    "2308.10792": {
        "arxivId": "2308.10792",
        "title": "Instruction Tuning for Large Language Models: A Survey"
    },
    "2210.10760": {
        "arxivId": "2210.10760",
        "title": "Scaling Laws for Reward Model Overoptimization"
    },
    "2301.00234": {
        "arxivId": "2301.00234",
        "title": "A Survey for In-context Learning"
    },
    "2012.00955": {
        "arxivId": "2012.00955",
        "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"
    },
    "2309.05463": {
        "arxivId": "2309.05463",
        "title": "Textbooks Are All You Need II: phi-1.5 technical report"
    },
    "2306.05424": {
        "arxivId": "2306.05424",
        "title": "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models"
    },
    "2004.14373": {
        "arxivId": "2004.14373",
        "title": "ToTTo: A Controlled Table-To-Text Generation Dataset"
    },
    "2306.03341": {
        "arxivId": "2306.03341",
        "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"
    },
    "2302.12813": {
        "arxivId": "2302.12813",
        "title": "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"
    },
    "2306.04751": {
        "arxivId": "2306.04751",
        "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources"
    },
    "2212.09251": {
        "arxivId": "2212.09251",
        "title": "Discovering Language Model Behaviors with Model-Written Evaluations"
    },
    "2104.05938": {
        "arxivId": "2104.05938",
        "title": "QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"
    },
    "2303.08896": {
        "arxivId": "2303.08896",
        "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"
    },
    "2206.06520": {
        "arxivId": "2206.06520",
        "title": "Memory-Based Model Editing at Scale"
    },
    "2305.11738": {
        "arxivId": "2305.11738",
        "title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing"
    },
    "2210.09150": {
        "arxivId": "2210.09150",
        "title": "Prompting GPT-3 To Be Reliable"
    },
    "2201.03514": {
        "arxivId": "2201.03514",
        "title": "Black-Box Tuning for Language-Model-as-a-Service"
    },
    "2306.13063": {
        "arxivId": "2306.13063",
        "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"
    },
    "2304.13734": {
        "arxivId": "2304.13734",
        "title": "The Internal State of an LLM Knows When its Lying"
    },
    "2305.16355": {
        "arxivId": "2305.16355",
        "title": "PandaGPT: One Model To Instruction-Follow Them All"
    },
    "2305.14627": {
        "arxivId": "2305.14627",
        "title": "Enabling Large Language Models to Generate Text with Citations"
    },
    "2210.08726": {
        "arxivId": "2210.08726",
        "title": "RARR: Researching and Revising What Language Models Say, Using Language Models"
    },
    "2304.05613": {
        "arxivId": "2304.05613",
        "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning"
    },
    "2307.10169": {
        "arxivId": "2307.10169",
        "title": "Challenges and Applications of Large Language Models"
    },
    "2303.12528": {
        "arxivId": "2303.12528",
        "title": "MEGA: Multilingual Evaluation of Generative AI"
    },
    "2305.13534": {
        "arxivId": "2305.13534",
        "title": "How Language Model Hallucinations Can Snowball"
    },
    "1702.04066": {
        "arxivId": "1702.04066",
        "title": "JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction"
    },
    "2112.08542": {
        "arxivId": "2112.08542",
        "title": "QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization"
    },
    "2304.08354": {
        "arxivId": "2304.08354",
        "title": "Tool Learning with Foundation Models"
    },
    "2105.10311": {
        "arxivId": "2105.10311",
        "title": "Pretrained Language Models for Text Generation: A Survey"
    },
    "2306.14565": {
        "arxivId": "2306.14565",
        "title": "Aligning Large Multi-Modal Model with Robust Instruction Tuning"
    },
    "2204.07931": {
        "arxivId": "2204.07931",
        "title": "On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?"
    },
    "2206.04624": {
        "arxivId": "2206.04624",
        "title": "Factuality Enhanced Language Models for Open-Ended Text Generation"
    },
    "2305.11747": {
        "arxivId": "2305.11747",
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models"
    },
    "2005.03642": {
        "arxivId": "2005.03642",
        "title": "On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation"
    },
    "2004.00345": {
        "arxivId": "2004.00345",
        "title": "Editable Neural Networks"
    },
    "2307.08701": {
        "arxivId": "2307.08701",
        "title": "AlpaGasus: Training A Better Alpaca with Fewer Data"
    },
    "2010.08712": {
        "arxivId": "2010.08712",
        "title": "Factual Error Correction for Abstractive Summarization Models"
    },
    "2305.14552": {
        "arxivId": "2305.14552",
        "title": "Sources of Hallucination by Large Language Models on Inference Tasks"
    },
    "2103.15025": {
        "arxivId": "2103.15025",
        "title": "On Hallucination and Predictive Uncertainty in Conditional Language Generation"
    },
    "2202.01110": {
        "arxivId": "2202.01110",
        "title": "A Survey on Retrieval-Augmented Text Generation"
    },
    "2306.04528": {
        "arxivId": "2306.04528",
        "title": "PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts"
    },
    "2305.14795": {
        "arxivId": "2305.14795",
        "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions"
    },
    "2307.13528": {
        "arxivId": "2307.13528",
        "title": "FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"
    },
    "2305.14739": {
        "arxivId": "2305.14739",
        "title": "Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"
    },
    "2305.12740": {
        "arxivId": "2305.12740",
        "title": "Can We Edit Factual Knowledge by In-Context Learning?"
    },
    "2301.09785": {
        "arxivId": "2301.09785",
        "title": "Transformer-Patcher: One Mistake worth One Neuron"
    },
    "2305.16739": {
        "arxivId": "2305.16739",
        "title": "AlignScore: Evaluating Factual Consistency with A Unified Alignment Function"
    },
    "2308.07317": {
        "arxivId": "2308.07317",
        "title": "Platypus: Quick, Cheap, and Powerful Refinement of LLMs"
    },
    "2307.04964": {
        "arxivId": "2307.04964",
        "title": "Secrets of RLHF in Large Language Models Part I: PPO"
    },
    "2104.08704": {
        "arxivId": "2104.08704",
        "title": "A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation"
    },
    "2305.03268": {
        "arxivId": "2305.03268",
        "title": "Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework"
    },
    "2307.13702": {
        "arxivId": "2307.13702",
        "title": "Measuring Faithfulness in Chain-of-Thought Reasoning"
    },
    "2307.03987": {
        "arxivId": "2307.03987",
        "title": "A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"
    },
    "2211.14876": {
        "arxivId": "2211.14876",
        "title": "Dense Text Retrieval Based on Pretrained Language Models: A Survey"
    },
    "2203.05115": {
        "arxivId": "2203.05115",
        "title": "Internet-augmented language models through few-shot prompting for open-domain question answering"
    },
    "2303.16104": {
        "arxivId": "2303.16104",
        "title": "Hallucinations in Large Multilingual Translation Models"
    },
    "2204.11454": {
        "arxivId": "2204.11454",
        "title": "Natural Language to Code Translation with Execution"
    },
    "2309.11495": {
        "arxivId": "2309.11495",
        "title": "Chain-of-Verification Reduces Hallucination in Large Language Models"
    },
    "2305.18153": {
        "arxivId": "2305.18153",
        "title": "Do Large Language Models Know What They Don't Know?"
    },
    "2305.13300": {
        "arxivId": "2305.13300",
        "title": "Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts"
    },
    "2309.03883": {
        "arxivId": "2309.03883",
        "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"
    },
    "2308.06394": {
        "arxivId": "2308.06394",
        "title": "Detecting and Preventing Hallucinations in Large Vision Language Models"
    },
    "2307.01850": {
        "arxivId": "2307.01850",
        "title": "Self-Consuming Generative Models Go MAD"
    },
    "2105.11269": {
        "arxivId": "2105.11269",
        "title": "Neural Machine Translation with Monolingual Translation Memory"
    },
    "2307.11019": {
        "arxivId": "2307.11019",
        "title": "Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"
    },
    "2308.10168": {
        "arxivId": "2308.10168",
        "title": "Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?"
    },
    "2305.13281": {
        "arxivId": "2305.13281",
        "title": "LM vs LM: Detecting Factual Errors via Cross Examination"
    },
    "2307.03917": {
        "arxivId": "2307.03917",
        "title": "On Decoder-Only Architecture For Speech-to-Text and Large Language Model Integration"
    },
    "2305.15852": {
        "arxivId": "2305.15852",
        "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"
    },
    "2307.16877": {
        "arxivId": "2307.16877",
        "title": "Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering"
    },
    "2305.19187": {
        "arxivId": "2305.19187",
        "title": "Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models"
    },
    "2205.11388": {
        "arxivId": "2205.11388",
        "title": "StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models"
    },
    "2111.07408": {
        "arxivId": "2111.07408",
        "title": "Time Waits for No One! Analysis and Challenges of Temporal Misalignment"
    },
    "2307.05300": {
        "arxivId": "2307.05300",
        "title": "Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration"
    },
    "2305.18248": {
        "arxivId": "2305.18248",
        "title": "Do Language Models Know When They\u2019re Hallucinating References?"
    },
    "2307.11768": {
        "arxivId": "2307.11768",
        "title": "Question Decomposition Improves the Faithfulness of Model-Generated Reasoning"
    },
    "2307.15337": {
        "arxivId": "2307.15337",
        "title": "Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"
    },
    "2305.01651": {
        "arxivId": "2305.01651",
        "title": "Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge"
    },
    "2307.06908": {
        "arxivId": "2307.06908",
        "title": "Generating Benchmarks for Factuality Evaluation of Language Models"
    },
    "2305.14002": {
        "arxivId": "2305.14002",
        "title": "Improving Language Models via Plug-and-Play Retrieval Feedback"
    },
    "2212.08597": {
        "arxivId": "2212.08597",
        "title": "Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better"
    },
    "2102.02810": {
        "arxivId": "2102.02810",
        "title": "Controlling hallucinations at word level in data-to-text generation"
    },
    "2303.15621": {
        "arxivId": "2303.15621",
        "title": "ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization"
    },
    "2203.03802": {
        "arxivId": "2203.03802",
        "title": "Understanding Iterative Revision from Human-Written Text"
    },
    "2308.03958": {
        "arxivId": "2308.03958",
        "title": "Simple synthetic data reduces sycophancy in large language models"
    },
    "2306.09296": {
        "arxivId": "2306.09296",
        "title": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"
    },
    "2305.13269": {
        "arxivId": "2305.13269",
        "title": "Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases"
    },
    "2304.10513": {
        "arxivId": "2304.10513",
        "title": "Why Does ChatGPT Fall Short in Providing Truthful Answers?"
    },
    "2306.05212": {
        "arxivId": "2306.05212",
        "title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit"
    },
    "2305.00955": {
        "arxivId": "2305.00955",
        "title": "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"
    },
    "2001.03830": {
        "arxivId": "2001.03830",
        "title": "Revisiting Challenges in Data-to-Text Generation with Fact Grounding"
    },
    "2305.06311": {
        "arxivId": "2305.06311",
        "title": "Automatic Evaluation of Attribution by Large Language Models"
    },
    "2303.11315": {
        "arxivId": "2303.11315",
        "title": "Context-faithful Prompting for Large Language Models"
    },
    "2203.16747": {
        "arxivId": "2203.16747",
        "title": "How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"
    },
    "2307.10236": {
        "arxivId": "2307.10236",
        "title": "Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models"
    },
    "2208.05309": {
        "arxivId": "2208.05309",
        "title": "Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation"
    },
    "2211.03318": {
        "arxivId": "2211.03318",
        "title": "Fixing Model Bugs with Natural Language Patches"
    },
    "2305.14908": {
        "arxivId": "2305.14908",
        "title": "PURR: Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions"
    },
    "2307.06290": {
        "arxivId": "2307.06290",
        "title": "Instruction Mining: High-Quality Instruction Data Selection for Large Language Models"
    },
    "2305.04757": {
        "arxivId": "2305.04757",
        "title": "Augmented Large Language Models with Parametric Knowledge Guiding"
    },
    "2305.13068": {
        "arxivId": "2305.13068",
        "title": "Making Language Models Better Tool Learners with Execution Feedback"
    },
    "2309.03118": {
        "arxivId": "2309.03118",
        "title": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs"
    },
    "2305.13669": {
        "arxivId": "2305.13669",
        "title": "Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"
    },
    "2309.09558": {
        "arxivId": "2309.09558",
        "title": "Summarization is (Almost) Dead"
    },
    "2205.11482": {
        "arxivId": "2205.11482",
        "title": "Tracing Knowledge in Language Models Back to the Training Data"
    },
    "2307.01379": {
        "arxivId": "2307.01379",
        "title": "Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models"
    },
    "2109.05487": {
        "arxivId": "2109.05487",
        "title": "Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation"
    },
    "2212.10711": {
        "arxivId": "2212.10711",
        "title": "Task Ambiguity in Humans and Language Models"
    },
    "2309.00240": {
        "arxivId": "2309.00240",
        "title": "FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking"
    },
    "2308.11764": {
        "arxivId": "2308.11764",
        "title": "Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models"
    },
    "2309.05936": {
        "arxivId": "2309.05936",
        "title": "Do PLMs Know and Understand Ontological Knowledge?"
    },
    "2305.14623": {
        "arxivId": "2305.14623",
        "title": "Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models"
    },
    "2211.06196": {
        "arxivId": "2211.06196",
        "title": "Improving Factual Consistency in Summarization with Compression-Based Post-Editing"
    },
    "2309.11064": {
        "arxivId": "2309.11064",
        "title": "Exploring the Relationship between LLM Hallucinations and Prompt Linguistic Nuances: Readability, Formality, and Concreteness"
    },
    "2309.02654": {
        "arxivId": "2309.02654",
        "title": "Zero-Resource Hallucination Prevention for Large Language Models"
    },
    "2306.16564": {
        "arxivId": "2306.16564",
        "title": "Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision"
    },
    "2307.00360": {
        "arxivId": "2307.00360",
        "title": "BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer"
    },
    "2309.08594": {
        "arxivId": "2309.08594",
        "title": "\"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs"
    },
    "2308.04215": {
        "arxivId": "2308.04215",
        "title": "Hybrid-RACA: Hybrid Retrieval-Augmented Composition Assistance for Real-time Text Prediction"
    }
}